#### 简短概要
这篇名为《思维之树：利用大型语言模型进行有意识的问题解决》的论文提出了一种独特的解码技术，利用大型语言模型。作者建议不仅仅一次性询问模型的输出，而是使用对语言模型输出的显式树搜索。这种方法允许分支和回溯，对于需要进行调查模式的任务特别有用。论文介绍了解码技术，并提出了预计能够表现良好的新任务。

#### 主要观点
- 🌳 该论文的主要观点是通过输入-输出提示来激发语言模型。这意味着指定任务并可选择提供输出格式。例如，可以要求模型以特定格式给老板写一封电子邮件。这种方法类似于思维链提示技术，其中模型被指示明确提供问题解决的中间步骤。然而，作者认为涉及模型输出的树搜索的思维之树技术可以产生更好的结果。模型本身评估树中的状态，允许分支和回溯。

#### 评估任务
- 🎮 论文探讨了三个主要任务来评估思维之树技术的有效性。第一个任务是24点游戏，模型被给定四个数字，并要求提供一个结果为24的数学表达式。作者指出，虽然该技术可以帮助模型解决这类问题，但提示需要非常具体，类似于编程算法。第二个任务是创意写作，要求模型生成一个故事。结果显示，思维之树技术在这个任务中的表现略优于其他提示方法，但差异不显著。第三个任务是迷你填字游戏，模型被给定一个字母网格和填入单词的线索。思维之树技术在这个任务中表现出极高的效果，因为它允许回溯和探索不同的路径。

#### 剪枝和回溯的影响
- 🌱 论文提出了几种消融实验，评估了剪枝和回溯对思维之树技术性能的影响。结果显示，剪枝和回溯显著提高了模型解决填字游戏的能力。有趣的是，在评估过程中添加一个始终选择最佳思维的神谕，进一步提高了性能。然而，对单词和字母成功率的影响并不显著。作者还指出，去除剪枝或回溯会导致解决的游戏总数减少，表明这些技术在规划和探索中的重要性。

#### 总结
- 📚 总体而言，该论文提出了一种利用大型语言模型进行问题解决任务的有趣方法。思维之树技术以其树搜索和回溯能力，在需要探索和推理的任务中显示出潜力。然而，当前实现严重依赖于明确的提示和约束，限制了其通用性。未来的研究应该专注于开发一种更灵活和通用的问题解决方法，利用语言模型的能力，而无需特定的提示。

### Detailed Summary
The paper titled "Tree of Thoughts: Deliberate Problem Solving with Large Language Models" proposes a decoding technique that utilizes large language models in a unique way. Instead of simply asking the model for its output once, the authors suggest using an explicit tree search over the outputs of the language model. This approach allows for branching off and backtracking, which can be particularly useful for tasks that require a pattern of investigation. The paper introduces the decoding technique and presents new tasks where it is expected to perform well.

The main proposition of the paper is to prompt a language model using input-output prompting. This means specifying the task and optionally providing an output format. For example, one could ask the model to write an email to their boss in a specific format. This approach is similar to the Chain of Thought prompting technique, where the model is instructed to explicitly provide intermediate steps in problem-solving. However, the authors argue that the Tree of Thoughts technique, which involves a tree search over the model's outputs, can yield better results. The model itself evaluates the states in the tree, allowing for branching and backtracking.

The paper explores three main tasks to evaluate the effectiveness of the Tree of Thoughts technique. The first task is the game of 24, where the model is given four numbers and asked to come up with a mathematical expression that results in 24. The authors note that while the technique can help the model solve these types of problems, the prompts need to be very specific, resembling programming algorithms. The second task is creative writing, where the model is asked to generate a story. The results show that the Tree of Thoughts technique performs slightly better than other prompting methods, but the difference is not significant. The third task is mini crosswords, where the model is given a grid of letters and clues to fill in the words. The Tree of Thoughts technique proves to be highly effective in this task, as it allows for backtracking and exploration of different paths.

The authors acknowledge that the prompts used in the evaluation tasks are quite specific and resemble programming algorithms. They argue that the goal of their research is not to solve specific tasks, as those can be readily solved with specialized NLP pipelines. Instead, they aim to develop a general problem-solving approach that leverages language models. However, the current implementation of the Tree of Thoughts technique relies heavily on explicit prompts and constraints, which limits its generality.

The paper presents several ablations to evaluate the impact of pruning and backtracking on the performance of the Tree of Thoughts technique. The results show that pruning and backtracking significantly improve the model's ability to solve crossword puzzles. Interestingly, the addition of an oracle, which always selects the best thought during evaluation, further improves performance. However, the impact on word and letter success rates is not substantial. The authors also note that removing pruning or backtracking leads to a decrease in the total number of solved games, indicating the importance of these techniques in planning and exploration.

Overall, the paper presents an interesting approach to utilizing large language models in problem-solving tasks. The Tree of Thoughts technique, with its tree search and backtracking capabilities, shows promise in tasks that require exploration and reasoning. However, the current implementation heavily relies on explicit prompts and constraints, limiting its generality. Future research should focus on developing a more flexible and general problem-solving approach that leverages the capabilities of language models without the need for specific prompts.