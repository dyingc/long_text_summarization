ç®€è¦æ¦‚è¿°ï¼š
æœ¬æ–‡è®¨è®ºäº†æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨Transformerä¸­çš„åº”ç”¨ã€‚æ³¨æ„åŠ›æœºåˆ¶å…è®¸æ¨¡å‹é›†ä¸­å…³æ³¨ä¸ä»»åŠ¡ç›¸å…³çš„è¾“å…¥æ•°æ®çš„æŸäº›éƒ¨åˆ†ã€‚è¯¥æœºåˆ¶æ¶‰åŠä»è¾“å…¥æ•°æ®ä¸­ç”ŸæˆæŸ¥è¯¢å’Œé”®çŸ©é˜µï¼Œç„¶åä½¿ç”¨å®ƒä»¬è®¡ç®—æƒé‡çŸ©é˜µï¼Œè¯¥çŸ©é˜µç¡®å®šæ¯ä¸ªæ ‡è®°åº”æ¥æ”¶å¤šå°‘å…³æ³¨ã€‚æƒé‡çŸ©é˜µæ˜¯ä½¿ç”¨æŸ¥è¯¢å’Œé”®ä¹‹é—´çš„å¤–ç§¯è®¡ç®—çš„ï¼Œè¿™å…è®¸æ¯ä¸ªæ ‡è®°å‚ä¸åˆ°æ¯ä¸ªå…¶ä»–æ ‡è®°çš„è®¡ç®—ä¸­ã€‚ç„¶åä½¿ç”¨æƒé‡çŸ©é˜µè®¡ç®—å€¼çš„åŠ æƒå’Œï¼Œè¿™æ˜¯æ³¨æ„åŠ›æœºåˆ¶çš„è¾“å‡ºã€‚

äº®ç‚¹ï¼š
- ğŸ¤– æ³¨æ„åŠ›æœºåˆ¶å…è®¸æ¨¡å‹é›†ä¸­å…³æ³¨ä¸ä»»åŠ¡ç›¸å…³çš„è¾“å…¥æ•°æ®çš„æŸäº›éƒ¨åˆ†ã€‚
- ğŸ§  æ³¨æ„åŠ›æœºåˆ¶å¯ä»¥åˆ†è§£æˆéƒ¨åˆ†ä»¥å‡å°‘å†…å­˜ä½¿ç”¨ï¼Œä½†è¿™ä¼šå¢åŠ è®¡ç®—æ—¶é—´ã€‚
- ğŸ¤– æ³¨æ„åŠ›è‡ªç”±Transformerä½¿ç”¨ä»æ•°æ®ä¸­å­¦ä¹ çš„å›ºå®šæƒé‡çŸ©é˜µæ›¿æ¢æŸ¥è¯¢å’Œé”®ä¹‹é—´çš„å¤–ç§¯ã€‚è¿™å…è®¸æ›´å¥½çš„å¯æ‰©å±•æ€§ï¼Œä½†å›ºå®šæƒé‡çŸ©é˜µä¸å¦‚åŸå§‹æ³¨æ„åŠ›æœºåˆ¶å¼ºå¤§ã€‚
- ğŸ§  rwkvæ˜¯ä¸€ç§æ–°æ–¹æ³•ï¼Œå®ƒå­¦ä¹ ä¸€ä¸ªå‘é‡è€Œä¸æ˜¯æƒé‡çŸ©é˜µã€‚è¯¥å‘é‡å®šä¹‰äº†è¿‡å»å¯¹éšè—çŠ¶æ€çš„æ¯ä¸ªç»´åº¦çš„å½±å“ç¨‹åº¦ï¼Œå¹¶æ ¹æ®æ ‡è®°ä¸è¿‡å»çš„è·ç¦»ä»¥åŠæ¶‰åŠå…¶å†å²çš„ç»´åº¦çš„å½±å“ç¨‹åº¦è®¡ç®—æ¯ä¸ªæ ‡è®°çš„æƒé‡ã€‚è¿™ä¸ªæƒé‡ç„¶åè¢«ä¸€ä¸ªä¾èµ–äºå½“å‰æ ‡è®°çš„é”®å€¼è°ƒåˆ¶ã€‚è¿™ç§æ–¹æ³•åœ¨æ³¨æ„åŠ›è‡ªç”±Transformerçš„çµæ´»æ€§å’ŒåŸå§‹æ³¨æ„åŠ›æœºåˆ¶çš„å¯æ‰©å±•æ€§ä¹‹é—´å–å¾—äº†å¹³è¡¡ã€‚

æ—¶é—´å˜æ¢å™¨ï¼š
ç®€è¦æ¦‚è¿°ï¼š
æœ¬æ–‡è®¨è®ºäº†ä¸€ç§åä¸ºTimeSformerçš„æ–°å‹ç¥ç»ç½‘ç»œæ¶æ„ï¼Œå®ƒæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ä½¿ç”¨çš„Transformeræ¶æ„çš„å˜ä½“ã€‚TimeSformeræ—¨åœ¨å¤„ç†è§†é¢‘æ•°æ®ï¼Œè¿™æ˜¯ä¸€ç§é¡ºåºæ•°æ®ç±»å‹ï¼Œä¸åŒäºæ–‡æœ¬æ•°æ®ã€‚TimeSformerç±»ä¼¼äºTransformerï¼Œå› ä¸ºå®ƒä½¿ç”¨è‡ªæˆ‘æ³¨æ„æœºåˆ¶æ¥å¤„ç†è¾“å…¥æ•°æ®ï¼Œä½†å®ƒè¿˜åŒ…æ‹¬ä¸€ç§ç§°ä¸ºTime Mixingæ¨¡å—çš„æ–°ç±»å‹æ¨¡å—ï¼Œè¯¥æ¨¡å—å…è®¸å…¶å¤„ç†é¡ºåºæ•°æ®ã€‚

äº®ç‚¹ï¼š
- ğŸ¥ TimeSformeræ—¨åœ¨å¤„ç†è§†é¢‘æ•°æ®ï¼Œè¿™æ˜¯ä¸€ç§é¡ºåºæ•°æ®ç±»å‹ï¼Œä¸åŒäºæ–‡æœ¬æ•°æ®ã€‚
- ğŸ¤– TimeSformerç±»ä¼¼äºTransformerï¼Œå› ä¸ºå®ƒä½¿ç”¨è‡ªæˆ‘æ³¨æ„æœºåˆ¶æ¥å¤„ç†è¾“å…¥æ•°æ®ï¼Œä½†å®ƒè¿˜åŒ…æ‹¬ä¸€ç§ç§°ä¸ºTime Mixingæ¨¡å—çš„æ–°ç±»å‹æ¨¡å—ï¼Œè¯¥æ¨¡å—å…è®¸å…¶å¤„ç†é¡ºåºæ•°æ®ã€‚
- ğŸ¥ TimeSformerç”±æ¨¡å‹çš„é‡å¤åº”ç”¨ç»„æˆï¼Œå…¶ä¸­ç›¸åŒçš„æ¨¡å‹è¿ç»­åº”ç”¨äºä¸‰ä¸ªæ ‡è®°ã€‚æ¨¡å‹ç”±ä¸€åˆ—ç»„æˆï¼Œå®ƒæœ‰ä¸€ä¸ªå¼€å§‹ï¼Œå³æ ‡è®°åµŒå…¥ï¼Œä¸€ä¸ªç»“æŸï¼Œå³è¯­è¨€å»ºæ¨¡å¤´ï¼Œä¸­é—´ç”±ä¸€ç³»åˆ—å±‚ç»„æˆã€‚æ¯ä¸ªå±‚éƒ½æœ‰ä¸€ä¸ªTime Mixæ¨¡å—å’Œä¸€ä¸ªChannel Mixæ¨¡å—ï¼Œè¿™äº›æ¨¡å—åœ¨åºåˆ—ä¸­é‡å¤å‡ºç°ã€‚
- ğŸ¤– TimeSformerçš„Channel Mixingå—ç±»ä¼¼äºå…·æœ‰ä¸€ä¸ªéçº¿æ€§å’Œä¸€ä¸ªé—å¿˜é—¨çš„å‰é¦ˆç¥ç»ç½‘ç»œã€‚Channel Mixingå—ä¸­çš„çº¿æ€§å±‚æ··åˆé€šé“ï¼Œè¿™æ„å‘³ç€æ¯ä¸ªç»´åº¦éƒ½å¯ä»¥ä»æ¯ä¸ªå…¶ä»–ç»´åº¦è·å¾—è¾“å…¥ã€‚Time Mixingå—å§‹ç»ˆä»ä¸Šä¸€ä¸ªæ—¶é—´æ­¥éª¤è·å–è¾“å…¥ï¼Œå¹¶åœ¨å½“å‰è¾“å…¥å’Œä¸Šä¸€ä¸ªè¾“å…¥ä¹‹é—´è¿›è¡Œçº¿æ€§æ’å€¼ã€‚è¿™æ„å‘³ç€TimeSformerä¸ä»…åƒä¸€èˆ¬çš„RNNä¸€æ ·è·å–å½“å‰è¾“å…¥å’Œä¹‹å‰çš„éšè—çŠ¶æ€ï¼Œè€Œä¸”è¿˜è·å–å½“å‰è¾“å…¥ã€ä¸Šä¸€ä¸ªè¾“å…¥å’Œéšè—çŠ¶æ€ã€‚
- ğŸ¥ TimeSformerè¿˜æœ‰ç¬¬äºŒè¡Œï¼Œå³çŠ¶æ€ã€‚Time Mixingæ¨¡å—æ˜¯æ¨¡å‹çš„å®é™…å¾ªç¯éƒ¨åˆ†ã€‚TimeSformerè®¡ç®—Rï¼Œè¿™åªæ˜¯X tildeä¹˜ä»¥Wä¹˜ä»¥å‰é¦ˆå±‚ï¼Œç„¶åæˆä¸ºå¸¦æœ‰é€å…ƒç´ ä¹˜æ³•çš„é—å¿˜é—¨ã€‚TimeSformerè¿˜æœ‰ä¸€ä¸ªè¾“å‡ºå‰é¦ˆå±‚ï¼Œå®ƒæ˜¯å¯ä»¥æ›´æ”¹ç»´åº¦å’Œå…¶ä»–å‚æ•°çš„æŠ•å½±ã€‚
- ğŸ¤– TimeSformerå¯ä»¥åœ¨æ—¶é—´å¹¶è¡Œå’Œæ—¶é—´é¡ºåºæ¨¡å¼ä¸‹ä½¿ç”¨ï¼Œä½¿å…¶çµæ´»ä¸”é€‚åº”ä¸åŒçš„ç”¨ä¾‹ã€‚

### Detailed Summary
The article discusses two new neural network architectures, the TimeSformer and the Performer, which are designed to improve the efficiency and accuracy of processing sequential data such as videos, audio, and natural language. The TimeSformer is based on the Transformer architecture, which has been successful in natural language processing tasks, but it uses a temporal convolutional layer instead of an attention mechanism to process the input sequence. This allows the TimeSformer to process the entire input sequence at once and mix information across time, making it a powerful tool for video and audio processing tasks. The TimeSformer can be used in both time-parallel and time-sequential modes, making it flexible and adaptable to different use cases.

The Performer, on the other hand, is designed to improve the efficiency of attention mechanisms in natural language processing tasks. The model uses a linear attention mechanism, which allows it to scale more efficiently than traditional attention mechanisms. The Performer performs similarly to other similarly sized Transformers, but there are some qualitative differences that need to be explored further. The model is able to scale more efficiently than traditional attention mechanisms because it uses a linear attention mechanism, which allows it to perform well on language modeling tasks. However, the model has limitations, including its inability to recall minutiae information over very long contexts, which may make it less effective for tasks that require recalling such information.

The article notes that more research is needed to determine the qualitative differences between the Performer and other models, as well as to explore the limitations of the model's recurrent architecture. The article concludes with a discussion of some interesting experiments that were conducted with the Performer, including a visualization of how the model considers past information at different layers and a demonstration of how the model processes input tokens. The visualization showed that as the model moves up the layers, it considers the past more and more, while the demonstration showed that the model processes input tokens in a way that allows it to carry information from lower layers to higher layers.

The TimeSformer is a new type of neural network architecture that is designed to process sequential data, specifically video data. The TimeSformer is similar to the Transformer architecture used in natural language processing, but it includes a new type of module called the Time Mixing module, which allows it to process sequential data. The TimeSformer has the same trade-offs as attention-free Transformers, but it is composed of a recurrent application of the model, where the same model is applied to three tokens in succession. The model is composed of one column, and it has a beginning, which is a token embedding, an end, which is a language modeling head, and in the middle, it is composed of a series of layers. Each layer has a Time Mix module and a Channel Mix module, which are repeated in a sequence. The purpose of the left branches of these computations is to make a decision about how much of the input signal to accept and send up to the next layer.

The Channel Mixing block is similar to a feed-forward neural network with one non-linearity and a forget gate as another non-linearity. The linear layers in the Channel Mixing block mix the channels, which means that every dimension can get inputs from every other dimension. The Time Mixing block always takes the input from the last time step and linearly interpolates between the current input and the last input. This means that the TimeSformer not only takes the current input and the hidden state from before, like in a general RNN, but it also takes the current input, the last input, and the hidden state onto these.

The TimeSformer also has a second line, which are the states. The Time Mixing module is the actual recurrent part of the model. The TimeSformer computes R, which is just X tilde times W times a feed-forward layer, and that becomes the forget gate with an element-wise multiplication. The TimeSformer also has an output feed-forward layer, which is a projection that can change the dimensionality and other parameters. The K and V are computed similarly to the original Transformer architecture, which is just the input times a linear layer.

The Performer is a new type of neural network architecture that is designed to improve the efficiency of attention mechanisms in natural language processing tasks. The model uses a linear attention mechanism, which allows it to scale more efficiently than traditional attention mechanisms. The Performer performs similarly to other similarly sized Transformers, but there are some qualitative differences that need to be explored further. The model is able to scale more efficiently than traditional attention mechanisms because it uses a linear attention mechanism, which allows it to perform well on language modeling tasks. However, the model has limitations, including its inability to recall minutiae information over very long contexts, which may make it less effective for tasks that require recalling such information.

The article notes that more research is needed to determine the qualitative differences between the Performer and other models, as well as to explore the limitations of the model's recurrent architecture. The article concludes with a discussion of some interesting experiments that were conducted with the Performer, including a visualization of how the model considers past information at different layers and a demonstration of how the model processes input tokens. The visualization showed that as the model moves up the layers, it considers the past more and more, while the demonstration showed that the model processes input tokens in a way that allows it to carry information from lower layers to higher layers.

Overall, both the TimeSformer and the Performer are promising new neural network architectures that have the potential to improve the efficiency and accuracy of processing sequential data. The TimeSformer's ability to process the entire input sequence at once and mix information across time makes it a powerful tool for video and audio processing tasks, while the Performer's linear attention mechanism allows it to scale more efficiently than traditional attention mechanisms in natural language processing tasks. However, more research is needed to fully understand the capabilities and limitations of both models.