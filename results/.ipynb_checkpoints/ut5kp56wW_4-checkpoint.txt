简要概述：
这篇论文提出了一种新的解码技术，称为“Tree of Thoughts”，可以用于大型语言模型的问题解决。该技术涉及对语言模型输出的显式树搜索，模型本身对不同状态进行评估。这允许分支和回溯，对于需要调查问题的任务非常有帮助。论文提出了一些新任务，预计解码技术将在这些任务上表现良好，并且结果表明它确实在这些任务上表现良好。

亮点：
- 🌳 “Tree of Thoughts”是一种新的解码技术，可以用于大型语言模型的问题解决。
- 🤖 该技术涉及对语言模型输出的显式树搜索，模型本身对不同状态进行评估。
- 🎓 论文提出了一些新任务，预计解码技术将在这些任务上表现良好。
- 🏆 结果表明，该技术在多个任务上表现优异，包括算术单词问题、逻辑推理和文本完成。
- 📝 “Tree of Thoughts”技术是一种思维链提示的类型，其中要求模型多次输出其思维，并且这些思维是根据输入提示进行评估的。
- 💻 该技术的实现是一种树搜索，可以是广度优先或深度优先，具有基于模型对思维的评估的修剪。
- 🌟 “Tree of Thoughts”技术是一种有前途的新方法，结合了语言模型的强大和算法的结构，允许更加深思熟虑和有效的问题解决。

### Detailed Summary
The article discusses a new approach to natural language processing (NLP) called "tree of thoughts" that aims to create a more interactive and iterative process for generating and evaluating language models. The approach involves breaking down a problem into smaller steps and evaluating each step before moving on to the next one. This leads to more evaluations of the language model, but also allows for more precise and accurate results.

The paper "Tree of Thoughts: Deliberate Problem Solving with Large Language Models" proposes a new decoding technique for using large language models. The technique involves an explicit tree search over the outputs of the language model, with the model itself valuing the different states. This allows for branching off and backtracking, which can be helpful for tasks where investigating the problem is important. The paper proposes some new tasks where the decoding technique is expected to work well, and the results show that it does indeed work well on those tasks.

The paper distinguishes between two types of prompting techniques: input-output prompting and Chain of Thought prompting. Input-output prompting involves specifying the task and optionally the output format, while Chain of Thought prompting instructs the model to explicitly make intermediate steps. The Tree of Thoughts technique is a type of Chain of Thought prompting, where the model is asked to output its thoughts multiple times, and then those thoughts are evaluated by the model with respect to the input prompt.

The Tree of Thoughts technique involves generating thoughts by sampling from the language model, and then evaluating those thoughts with respect to the input prompt. The thoughts are generated one at a time, and the model is asked to make one intermediate step at a time, rather than solving the problem completely. The thoughts can be sampled multiple times, or the model can be asked to output a list of thoughts. The thoughts are then evaluated by the model, either by assigning a value or by voting for the best thought.

The Tree of Thoughts technique is implemented as a tree search, either breadth-first or depth-first, with pruning based on the model's evaluation of the thoughts. The nodes of the tree represent the different thoughts generated by the model, and the edges represent the evaluation of those thoughts. The algorithm expands the node with the highest current value assigned to it, and backtracks when no nodes are above the value threshold.

The paper evaluates the Tree of Thoughts technique on several tasks, including arithmetic word problems, logical reasoning, and text completion. The results show that the technique outperforms other decoding techniques, including input-output prompting and Chain of Thought prompting. The authors suggest that the technique could be used for other tasks where deliberate problem-solving is important, such as creative writing or scientific discovery.

The article discusses a recent paper on the use of language models for problem-solving. The paper proposes a new approach to problem-solving that involves a language model exploring its own thoughts and backtracking when necessary. The authors of the paper demonstrate the effectiveness of their approach by applying it to crossword puzzles and other word games.

The paper's approach involves using a language model to generate possible solutions to a problem. The model then evaluates each solution and selects the best one. If the selected solution is not satisfactory, the model backtracks and tries again. The authors of the paper argue that this approach is more flexible and powerful than traditional problem-solving methods.

The paper's results show that the language model approach is effective at solving crossword puzzles and other word games. The authors of the paper also perform ablations to test the impact of different factors on the model's performance. They find that pruning and backtracking are important for the model's success, but that the model's performance is not greatly affected by the use of heuristics or oracles.

The article notes that the paper's approach is still limited in some ways. For example, the model still requires explicit prompts to guide its problem-solving process. The article suggests that future research should focus on developing a more general problem-solving model that does not require explicit prompts.

The article also discusses the potential applications of the paper's approach. The author suggests that the language model approach could be used in algorithms and other problem-solving tasks. The author notes that this could lead to a future where language models are integrated with classic algorithms to create more powerful problem-solving tools.

Overall, the tree of thoughts approach represents a promising new direction for NLP that emphasizes interactive and iterative problem-solving. However, further research is needed to determine its effectiveness in a wider range of applications and to develop more efficient implementation strategies.